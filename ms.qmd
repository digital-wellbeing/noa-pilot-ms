---
title: "Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players"
shorttitle: "Nintendo gaming and well-being"
author:
  - name: Nick Ballou
    corresponding: false
    orcid: 0000-0003-4126-0696
    email: nick@nickballou.com
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    roles:
      - conceptualization
      - data curation
      - methodology
      - formal analysis
      - writing
      
  - name: Matti Vuorre
    corresponding: false
    orcid: 0000-0001-5052-066X
    affiliations:
      - name: Tilburg University
      - name: University of Oxford
        department: Oxford Internet Institute
    roles:
      - methodology
      - funding acquisition
      - formal analysis
      - editing
      
  - name: Thomas Hakman
    corresponding: false
    orcid: 0009-0009-8292-2482
    email: nick@nickballou.com
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    roles:
      - data curation
      - validation
      - editing
      
  - name: Kristoffer Magnusson
    corresponding: false
    orcid: 0000-0003-0713-0556
    affiliations:
      - name: Karolinska Institute
      - name: University of Oxford
        department: Oxford Internet Institute
    roles:
      - methodology
      - editing
      
  - name: Andrew K Przybylski
    corresponding: true
    email: andy.pryzbylski@oii.ox.ac.uk
    orcid: 0000-0003-4126-0696
    affiliations:
      - name: University of Oxford
        department: Oxford Internet Institute
    roles:
      - conceptualization
      - funding acquisition
      - project administration
      - editing
abstract: "Studies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 704 US adults' time spent playing over 150 1st-party Nintendo Switch games (totaling 140k hours) relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past 2 weeks does not predict well-being, and extend these findings to a wider range of timescales (1 hour to 1 year). Results suggest that relationships, if present, dissipate within 2 hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasize the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent."
keywords: [video games, digital trace data, well-being]
author-note:
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    study-registration: This study was registered on the Open Science Framework (https://osf.io/sjqyt).
    # Acknowledge and cite data/materials to be shared.
    data-sharing: Data and materials are available at XXXXX. 
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: Data for this study was provided by Nintendo of America. Nintendo of America had no role in the design of the study, the analysis of the data, or decision to publish any results. The authors declare no other competing interests. 
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: ~ This research was supported by Huo Family Foundation and the UK Economic and Social Research Council (ESRC) (ES/W012626/1). KM was supported by Forskningsrå det för hälsa, arbetsliv och välfärd (2021-01284).
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
bibliography: references.bib
floatsintext: true # If true, tables and figures are mingled with the text instead of listed at the end of the document.
numbered-lines: false # Numbered lines (.pdf and .docx only)
meta-analysis: false
format:
  apaquarto-docx: default
  # apaquarto-html:
  #   documentmode: man
  #   code-fold: true
  #   code-summary: "Show the code"
  #   wordcount-html: default
  # apaquarto-pdf:
  #   documentmode: jou
---

```{r}
#| label: setup

knitr::opts_chunk$set(
  echo = knitr::is_html_output(), 
  warning = FALSE, 
  message = FALSE, 
  output = TRUE
)
```

```{r}
#| label: load-libraries

library(tidyverse)
library(lubridate)
library(knitr)
library(kableExtra)
library(dtplyr)
library(scales)
library(ggdist)
library(distributional)
library(mgcv)
library(patchwork)
library(see)
library(performance)
library(careless)
library(cowplot)
library(marginaleffects)
library(flextable)
library(ggstance)
library(crosstable)

options(scipen = 999)
```

```{r}
#| label: load-data

datSurveyRaw <- read_csv(paste0(Sys.getenv("DATA_PATH"), "survey.csv.gz"))
datRaw <- read_csv(paste0(Sys.getenv("DATA_PATH"), "telemetry.csv.gz")) |> 
  left_join(datSurveyRaw, by = "pid")
datDemo <- read_csv(paste0(Sys.getenv("DATA_PATH"), "demographics.csv.gz"))

```

```{r}
#| label: custom-functions

# Function for calculating playtime, relying on vectorized pmin()/pmax()
# When using the durations from Nintendo - we take the duration of sessions that begin or end during the playtime window, and weight them in case of partial sessions 
calculatePlaytime <- function(sessionStart, 
                              sessionEnd, 
                              recordedDate, 
                              duration, # column containing duration as calculated by nintendo
                              timeWindows, 
                              nintendo = FALSE # calculate duration based solely on start/end times (FALSE), or nintendo's heuristics (TRUE)
) {
  
  overlaps <- map(timeWindows, ~{
    overlapStart <- pmax(sessionStart, as_datetime(recordedDate) %m-% .x)
    overlapEnd <- pmin(sessionEnd, recordedDate)
    overlapTime <- interval(overlapStart, overlapEnd) / dhours(1)
    
    if (nintendo) {
      weight <- overlapTime/ (interval(sessionStart, sessionEnd) / dhours(1)) 
      overlap <- pmax(0, duration*weight) # if the overlap is negative, return 0
    } else {
      overlap <- pmax(0, overlapTime) # if the overlap is negative, return 0
    }
    
  })
  # Set the names of the list elements to correspond to the windows
  names(overlaps) <- if (nintendo) { paste0("overlapNintendo", names(timeWindows))} else { paste0("overlap", names(timeWindows)) }
  return(overlaps)
}

mytheme <- list(
  theme_bw() +
    theme(
      strip.background = element_rect(fill = "black"),
      strip.text = element_text(color = "white", size = 10),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(colour = "black", fill=NA, size=1),
      axis.text.y = element_text(size = 10, hjust = .5, vjust = -.015),
      axis.text.x = element_text(size = 10),
      axis.title.x = element_text(hjust = .45, size = 10, face = "bold"),
      axis.title.y = element_text(hjust = .45, size = 10, face = "bold"),
      legend.direction = "vertical",
      legend.text = element_text(size = 10)
    ),
  # coord_cartesian(clip = "off"),
  guides(alpha = "none", fill = guide_legend(reverse = TRUE))
)

# Labels for prettier figures
playtimeDict <- c(
  "1H" = "playtime1hr", "2H" = "playtime2hr", "6H" = "playtime6hr", "12H" = "playtime12hr",
  "1D" = "playtime1d", "3D" = "playtime3d", "1W" = "playtime1wk", "2W" = "playtime2wk",
  "1M" = "playtime1mo", "3M" = "playtime3mo", "6M" = "playtime6mo", "1Y" = "playtime1yr"
)

nintendoDict <- c(
  "1H" = "playtimeNintendo1hr", "2H" = "playtimeNintendo2hr","6H" = "playtimeNintendo6hr", "12H" = "playtimeNintendo12hr", 
  "1D" = "playtimeNintendo1d", "3D" = "playtimeNintendo3d", "1W" = "playtimeNintendo1wk", "2W" = "playtimeNintendo2wk",
  "1M" = "playtimeNintendo1mo", "3M" = "playtimeNintendo3mo", "6M" = "playtimeNintendo6mo", "1 Year" = "playtimeNintendo1yr"
)
  
playedDict <- c(
  "1H" = "played1hr", "2H" = "played2hr", "6H" = "played6hr", "12H" = "played12hr",
  "1D" = "played1d", "3D" = "played3d", "1W" = "played1wk", "2W" = "played2wk",
  "1M" = "played1mo", "3M" = "played3mo", "6M" = "played6mo", "1Y" = "played1yr"
)

```

Video games played on smartphones, computers, or home consoles are now a widely pursued form of leisure that involves social interaction, creativity, problem-solving, and growth [@BourgonjonEtAl2016Players]. Major firms like Nintendo have sold hundreds of millions of games consoles in recent years [@NintendoJapan2024Top] and online platforms like Steam typically have more than 30 million players online at any given time [@SteamCharts2024SteamCharts]. This staggering investment of human capital has inspired both national [@AmericanPsychiatricAssociation2013diagnostic] and international [@WorldHealthOrganization2018international] health bodies to focus on play as contributor to psychopathology.

The extent to which games might be understood as behaviorally addictive remains hotly debated [@AarsethEtAl2017scholars; @VanRooijEtAl2018weak; @BillieuxEtAl2017functional] and the broader scientific conversation has increasingly focused on how not just quantity, but also quality of play relates to player health. Although there is increasing recognition that not all screentime—or in the case of games, playtime—is created equal [@Orben2022Digital], it remains a major research focus. Research has identified a range of factors that co-determine how time spent with games relates to health: for example, aspects of a game’s design such as its social affordances [@CrenshawNardi2016It], the context of when and where one plays [@DrummondSauer2020Timesplitters], and players’ motivation [@BruhlmannEtAl2020Motivational].

In matters of health policy, overall time spent with games—regardless of what or why one plays—remains central to how games are thought to influence player outcomes. Parental control tools on platforms like Xbox and PlayStation foreground time limits as a primary means of enforcing healthy gaming behavior [@Robertson2021Taming]; for adults, a growing array of self-control tools, apps, and dashboards offer the ability to "limit or cut yourself off from apps and games" ([https://focusme.com](https://focusme.com/how-it-works/)), savings users "1.23 hours" (<https://www.opal.so>) or "up to 2.5 hours a day" ([https://freedom.to/](https://freedom.to/freedom-for-ios)). News media suggest time-based limits [e.g., @Saveva2023Healthy], often referencing the since-abandoned 2x2 rule from the American Academy of Pediatrics: no screen time for children under 2, and no more than 2 hours per day for children older than 2 [@Blum-RossLivingstone2018Trouble]. Likewise, the American Psychiatric Association’s description of Internet Gaming Disorder characterizes pathological engagement with games, in part, as involving ‘8-10 hours or more per day \[and or\] least 30 hours per week’ [@AmericanPsychiatricAssociation2013diagnostic, p. 796]. On a larger scale, time-based limits such as Korea’s 10-year Youth Protection Revision Act prohibited young people from playing games between 00:00 and 06:00 [@SangEtAl2017Mobile]. More recently, China put in place a three-hour weekly limit for under-18s [@FeinerKharpal2021China]. The effectiveness of such regulatory steps has been challenged [@zendle2023; @ChoiEtAl2018Effect].

A better understanding of how time spent with games relates to players’ health, for good or ill, is needed. Given that play takes many forms and happens across many different games, researchers greatly benefit from access to digital trace data—histories of user actions generated when interacting with technologies such as a game or online platform. Digital trace data can provide much greater detail about what, when, and how much people play than is possible in self-report data, which consistently shows substantial discrepancies compared to digital trace data collected by online platforms [@ErnalaEtAl2020How] and independent researchers [@ParryEtAl2021systematic] alike. Previous studies on games found that an additional hour of *Animal Crossing: New Horizons* trace data predicted just a 30-minute increase in self-reported play—a nearly 50% discrepancy [@JohannesEtAl2021video]---and that *Everquest 2* players' estimates correlated only r = .37 with logged estimates, with underestimates slightly more common than overestimates [@kahn2014].

Only a handful of studies have applied digital trace data to the study of games and well-being \[ @VuorreEtAl2022Time; @JohannesEtAl2021video; @BruhlmannEtAl2020Motivational; @LarrieuEtAl2023How\], in part because this data can be very difficult to acquire: researchers must build or rely on (often unstable) technical systems to log data themselves, or negotiate individual agreements with games companies who have historically been reluctant to share data [@Ballou2023Manifesto; @SeifEl-NasrEtAl2013game]. Where digital trace data has been collected, however, results have been informative. @BruhlmannEtAl2020Motivational used playtime and in-game behavior to identify subgroups of *League of Legends* players who had more negative in-game experiences. @JohannesEtAl2021video look at playtime in *Animal Crossing: New Horizons* and *PvZ: Battle for Neighborville* and found a positive but likely negligible correlation. A follow-up study expanded this to 7 games, finding that changes in playtime over the course of 6 weeks were unlikely to affect subsequent well-being [@VuorreEtAl2022Time]. @LarrieuEtAl2023How follow high-intensity *Rainbow 6: Siege* players and find no link between playtime and quality of life across any identified player types.

Though informative, this early work has a vital scope limitation: digital trace data was only available for a single game per player. It was not possible to know what other games a participant was, or was not, electing to play. Players regularly switch between games over the course of a day or week based on mood, available time, and social context [@ONeillEtAl2016Condensing; @BallouEtAl2024Registered]; data collected for one particular game may thus tell us little about *overall* playtime or its relation to well-being.

An important frontier for the field, therefore, is to collect holistic digital trace data that reflects behavior in not just one game, but all games played (which may include various games on one platform, such as Nintendo Switch or Steam, or all games played across several platforms a player uses). At present, our understanding of even basic phenomena such as the true volume of play in different demographics rely on the same inaccurate self-report data, itself often provided by market research firms using opaque methodologies. Capturing play at the platform level represents one step towards this goal of studying a player's complete gaming diet. To our knowledge, the only study to platform-level digital trace data to investigate player health is [@BallouEtAl2024Registered], which found no meaningful relationships between Xbox playtime and well-being over 3 months.

## Present Study

In the present research we report on a study conducted in collaboration with Nintendo of America, in which we independently recruited a large sample of adult video game players, surveyed them about their motivation and well-being, and joined these responses to digital trace data on Nintendo Switch video game play. Our central aim was to test the extent to which the amount of time participants spent playing related to their psychological well-being. Our analysis plan was preregistered at <https://osf.io/sjqyt>.

More specifically, our first hypothesis was to test whether the null relations reported in earlier work [@JohannesEtAl2021video; @VuorreEtAl2022Time; @BallouEtAl2024Registered] would replicate in an independent sample of play across the Nintendo platform. In our first hypothesis, we predicted that there will be no practically significant association between video game playtime in the previous 2 weeks and life satisfaction (H1a), affective valence (H1b), depressive symptoms (H1c), or general mental well-being (H1d).

We were also interested in understanding how relationships between play and well-being might depend on the choice of what time scale of play is considered relevant. To this end, we examined relationships between well-being and a wide range of time windows of play preceding the well-being question. While preregistered, the large number of models implicated in our analysis plan is prohibitively large to be aptly framed as a narrow hypothesis test. We therefore operationalize this as an exploratory research question: How does the relationship between playtime and well-being differ across different gaming observation windows ranging from 1 hour to 1 year?

Lastly, we investigated what factors might moderate the relationship between playtime and well-being. To test this exploratory question, we assessed potential moderation by gender, age, as well as a subjective sense of how players thought gaming had positive or negative relationships to various life domains such as work, relationships, school performance, and social health.

```{r}
#| label: calculate-playtime

# Define time windows we're interested in
timeWindows <- list(
  "1hr" = hours(1), "2hr" = hours(2), "6hr" = hours(6),
  "12hr" = hours(12), "1d" = hours(24), "3d" = days(3),
  "1wk" = weeks(1), "2wk" = weeks(2), "1mo" = months(1),
  "3mo" = months(3), "6mo" = months(6), "1yr" = months(12)
)

overlaps <- calculatePlaytime(datRaw$sessionStart, datRaw$sessionEnd, datRaw$recordedDate, datRaw$duration, timeWindows, nintendo = FALSE)
overlapsNintendo <- calculatePlaytime(datRaw$sessionStart, datRaw$sessionEnd, datRaw$recordedDate, datRaw$duration, timeWindows, nintendo = TRUE)

datAll <- datRaw |> 
  lazy_dt() |>
  # Add the time overlaps to the df 
  mutate(across(everything(), ~.x), !!!overlaps,
         across(everything(), ~.x), !!!overlapsNintendo) |> 
  mutate(
    impliedDuration = interval(sessionStart, sessionEnd) / dhours(1)
  ) |> 
  filter(duration < 24*60 & impliedDuration < 24) |> # drop implausible sessions lasting more than 24 hours
  group_by(pid) |>
  summarise(
    across(-starts_with("overlap"), first), # all survey columns are identical within participants, so we just take the first
    
    # The sub-one day intervals have no denominator
    playtime1hr = sum(overlap1hr),
    playtime2hr = sum(overlap2hr),
    playtime6hr = sum(overlap6hr),
    playtime12hr = sum(overlap12hr),
    playtime1d = sum(overlap1d),
    
    # Those longer than one day are divided by the number of days in the interval to indicate
    # mean hours of play per day during that period
    playtime3d = sum(overlap3d)/3,
    playtime1wk = sum(overlap1wk)/7,
    playtime2wk = sum(overlap2wk)/14,
    playtime1mo = sum(overlap1mo)/30,
    playtime3mo = sum(overlap3mo)/90,
    playtime6mo = sum(overlap6mo)/180,
    playtime1yr = sum(overlap1yr)/365,
    
    # repeat for nintendo duration
    playtimeNintendo1hr = sum(overlapNintendo1hr),
    playtimeNintendo2hr = sum(overlapNintendo2hr),
    playtimeNintendo6hr = sum(overlapNintendo6hr),
    playtimeNintendo12hr = sum(overlapNintendo12hr),
    playtimeNintendo1d = sum(overlapNintendo1d),
    
    playtimeNintendo3d = sum(overlapNintendo3d)/3,
    playtimeNintendo1wk = sum(overlapNintendo1wk)/7,
    playtimeNintendo2wk = sum(overlapNintendo2wk)/14,
    playtimeNintendo1mo = sum(overlapNintendo1mo)/30,
    playtimeNintendo3mo = sum(overlapNintendo3mo)/90,
    playtimeNintendo6mo = sum(overlapNintendo6mo)/180,
    playtimeNintendo1yr = sum(overlapNintendo1yr)/365,
  ) |> 
  
  # calculate binary versions of each playtime metric (i.e., played at all vs did not play at all)
  mutate(across(starts_with("playtime"),
                ~ . > 0,
                .names = "played{.col}"
         )) |> 
  rename_with(.fn = ~ str_replace(.x, "playtime", ""),
              .cols = starts_with("played")) |> 
  
  select(-(titleID:operationMode), -impliedDuration) |>  # drop telemetry columns; can still be accessed in datRaw
  as_tibble()

# Code used to identify item pairs with high sample correlations
# itemCorrelations <- psychsyn_critval(datAll |> select(where(is.numeric)))
```

```{r}
#| label: clean-survey

datAll <- datAll |> 
  
  ## Calculate well-being variables
  mutate(
    genderRC = ifelse(gender %in% c("Man","Woman",NA), gender, "Non-binary"),
    across(starts_with(c("wemwbs","promis","trojan","bangs","displacement")), ~case_when(
      . %in% c("Greatly interfered") ~ -3,
      . %in% c("Moderately interfered") ~ -2,
      . %in% c("Slightly interfered") ~ -1,
      . %in% c("No impact") ~ 0,
      . %in% c("1 - None of the time","Never","1 - Strongly disagree","1 \nStrongly Disagree","Slightly supported","1") ~ 1,
      . %in% c("2 - Rarely","Rarely","Moderately supported","2") ~ 2,
      . %in% c("3 - Some of the time","Sometimes","Greatly supported","3") ~ 3,
      . %in% c("4 - Often","Often","4Neither Agree nor Disagree","4") ~ 4,
      . %in% c("5 - All of the time","Always","5 - Strongly agree","5") ~ 5,
      . %in% c("6") ~ 6,
      . %in% c("7 Strongly agree") ~ 7,
      TRUE ~ NA_integer_))
  ) |> 
  rowwise() |> 
  mutate(
    meanWemwbs = mean(c_across(starts_with("wemwbs"))),
    meanPromis = mean(c_across(starts_with("promis"))),
    meanLifeFit = mean(c_across(starts_with("displacement")))
  ) |> 
  ungroup() |> 
  mutate(
    csas = rescale(csas, from = c(0,10), to = c(1,5)),
    affectiveValence = rescale(affectiveValence_1, from = c(1, 100), to = c(1, 5)),
    .keep = "unused"
    ) %>%
  
  # Here we run additional checks for potential careless responders using the (1) inter-item correlation and (2) longstring techniques.
  # In the first, we take the within-measure item pairs with the strongest correlation 
  # in the sample, and then identify the participants whose scores substantially differed, suggesting potential carelessness.
  #
  # In the second, we look at the number of consecutive identical answers. 
  # Together, this catches most participants who either gave identical answers to all questions or who chose answers semi-randomly. 
  
  mutate(
    longstring = longstring(select(., bangs_1:bangs_18)),
    intraIndVar = irv(select(., promis_1:promis_8),
                      na.rm = TRUE,
                      num.split = 1)
  ) |> 
  mutate(
    weirdLongstring = longstring > 8,
    weirdPromis = abs(promis_5 - promis_1) >= 4,
    weirdTrojan = abs(trojan_3 - trojan_1) >= 4,
    weirdBangs = abs(bangs_9 - bangs_8) >= 4,
    possibleCareless = ifelse(weirdLongstring | weirdPromis | weirdTrojan | weirdBangs, TRUE, FALSE)
  )
```

```{r}
#| label: apply-exclusions

## Apply exclusion criteria, as preregistered

nonResponders <- datAll |> 
  filter(is.na(recordedDate)) |> 
  pull(pid)

## Clock hackers (sessions taking place in the future)
clockHackers <- datRaw |>
  arrange(desc(sessionEnd)) |>
  filter(sessionEnd > "2024-05-20") |> 
  pull(pid) |> 
  unique()

## Players with no playtime in the last 3 months are dropped from all analyses
nonPlayers <- datAll |> 
  filter(!played3mo) |> 
  pull(pid) |> 
  unique()

# filter out in stages, in case of manual look at change in sample size after each 
dat <- datAll |> 
  filter(!pid %in% nonResponders) |> 
  filter(!pid %in% nonPlayers) |> 
  filter(!pid %in% clockHackers) |> 
  filter(possibleCareless %in% c(FALSE, NA)) |> 
  select(-starts_with(c("wemwbs","bangs","trojan","promis","timeUse","recent","weird")), -c(positives,problematicPlay,feedback))

numCareless <- table(datAll$possibleCareless)[2]
```

# Method

```{r}
#| label: fig-sankey
#| fig-align: center
#| fig-width: 8
#| fig-height: 6
#| fig-cap: "Participant flow, from recruitment to final sample"
#| apa-twocolumn: true

knitr::include_graphics("figures/sankey.png")
```

## Design and Recruitment

Our participant flow is shown in @fig-sankey. We recruited participants from Prolific, a participant recruitment platform, who were: (1) 18 years old, (2) proficient in English, (3) residents of the US, and (4) active video game players (self-defined, based on a \>0 response to Prolific's built-in screening item "How many hours per week do you play video games on average?"). We first distributed a screening questionnaire to 7649 participants asking which video game platforms they were active on; of these, 4184 indicated that they played games on Nintendo Switch.

We invited these participants to a second survey wherein they retrieved an account identifier from the Nintendo web interface (the events QR code, available at <https://accounts.nintendo.com/qrcode>), and shared it with us. This identifier is separate from their username, and cannot be used by anyone besides Nintendo (including ourselves) to link the player to personally identifiable information. A total of 1823 participants completed the linking process. We sent the account identifiers to Nintendo of America, who in turn sent us each player's pseudonymized play history from May 1, 2022 to present. Data collection began with a pilot study of 100 participants on Nov 15, 2023, which was combined with primary data collection from Feb 12, 2024 to May 6, 2024.

Of the participants who completed the linking process, 1607 had eligible Nintendo data (i.e., any play sessions of a 1st party game—a game published by Nintendo or one of its subsidiaries, as opposed to a third-party publisher—from May 1, 2022 to present). These 1607 were subsequently sent a well-being survey in Qualtrics (see Measures below). 1191 participants completed the well-being survey; our preregistered stopping rule went into effect when 5 or fewer participants per day completed the survey for 3 consecutive days.

As preregistered, we excluded 427 individuals who had 0 minutes of playtime during the previous 3 months, indicating that they are not active Nintendo players, and 26 people who logged more than 24 hours of playtime on any single day or who had a session that took place in the future, indicating a technical problem or manipulation of the system clock for in-game benefits. We further excluded 34 participants who displayed signs of careless responding (e.g., so-called straightlining or seemingly random responses). In total, we excluded 487 participants (some participants were excluded on multiple grounds), leading to a final sample of `r nrow(dat)`.

Participants were paid £0.15 for the 1-minute screening questionnaire, £3 for linking their data (\~5 minutes) plus a £2 bonus payment if data was successfully retrieved, and £4 for a 22-minute well-being survey. This study received approval from the University of Oxford Social Sciences and Humanities Interdivisional Research Ethics Committee (OII_C1A_23_107).

## Participants and Exclusions

```{r}
#| label: tbl-demographics
#| tbl-cap: "Participant Demographics"
#| apa-twocolumn: true

dat |> 
  left_join(datDemo, by = "pid") |> 
  select(age, gender, employment, eduLevel, ethnicity) |> 
  mutate(
    Age = age,
    Gender = ifelse(!(gender %in% c("Man","Woman")), 
                     "Non-binary or other gender identity", 
                     gender),
    `Employment Status` = ifelse(!(employment %in% c("Working full-time","Working part-time", "Student", "Not currently employed")), 
                     "Other employment status", 
                     employment),
    Ethnicity = ifelse(!(ethnicity %in% c("White","Asian","Mixed","Black")), 
                     "Other ethnicity", 
                     ethnicity),
    `Educational Level` = ifelse(!(eduLevel %in% c("University Bachelors Degree","Asian","Mixed","Black")), 
                     "Other ethnicity", 
                     eduLevel)
  ) |> 
  mutate(
    Gender = fct_relevel(Gender, sort(table(Gender), decreasing = TRUE) %>% names()),
    `Employment Status` = fct_relevel(`Employment Status`, sort(table(`Employment Status`), decreasing = TRUE) %>% names()),
    Ethnicity = fct_relevel(Ethnicity, sort(table(Ethnicity), decreasing = TRUE) %>% names()),
    `Educational Level` = fct_relevel(`Educational Level`, sort(table(`Educational Level`), decreasing = TRUE) %>% names())
  ) |> 
  crosstable(
    cols = c("Age","Gender","Employment Status","Ethnicity"),
    percent_digits = 1,
    funs = c("Mean (SD)" = meansd, "Median (IQR)" = mediqr, "Min / Max" = minmax)
  ) |> 
  crosstable::as_flextable() |> 
  set_header_labels(
    values = c(
      "Descriptor", "Variable", "Value")
  ) |>
  theme_apa() |> 
  fontsize(size = 8, part = "all") |>  # Adjust font size
  padding(padding = 0, part = "all")  # Adjust padding
```

Participant demographics are shown in @tbl-demographics. 

## Measures

Participants completed a self-report survey that took on average 22 minutes to complete. The survey included background factors such as demographics and life circumstances, a series of cognitive tasks, as well as self-report measures of time use, and motivations for video game play. We detail those measures we used in this study below but all study data are available at OSF (see supplementary materials).

**Video game playtime** was measured by collecting a record of each player's individual game sessions for all 1st party video games played on a Nintendo Switch. These data were provided by Nintendo of America. Playtime was calculated by summing the duration of all (partial) sessions that occur during a given time period relative to the participant's survey response, based on the logged session start and end times. For ease of interpretation, game play time in all observation periods longer 24 hours is reported as mean minutes of play per day. It is important to note that these data included only telemetry for games published by Nintendo and its close business partners (e.g. The Pokémon Company), but not games made by third party publishers (e.g. Electronic Arts). Nintendo-published games accounted for 63% of all playtime across our sample; the 37% of play data from 3rd-party games is therefore treated as missing. We return to this limitation in the discussion.

**General mental well-being** was measured with the WEMWBS [@TennantEtAl2007warwickedinburgh]. Players rated 14 statements about how they felt during the past 2 weeks such as "I’ve been dealing with problems well" and "I’ve been feeling good about myself" on a 5-point scale from 1 ("none of the time") to 5 ("all of the time"). Scores were calculated by taking the mean of all items.

**Depressive symptoms** was measured with the PROMIS Short Form 8a [@PilkonisEtAl2011item]. Players rated 8 statements about how they felt in the past 7 days such as "I felt hopeless" and "I felt I had nothing to look forward to" on a 5-point scale from 1 ("never") to 5 ("always"). Scores were calculated by taking the mean of all items.

**Life satisfaction** was measured with the one-item Cantril self-anchoring scale [@Cantril1965pattern]. Participants were prompted with ‘Please imagine a ladder with steps numbered from 0 at the bottom to 10 at the top. The top of the ladder represents the best possible life for you, and the bottom of the ladder represents the worst possible life for you. On which step of the ladder would you say you personally feel you stood over the past two weeks?’. Participants responded on a scale from 0 to 10, which was rescaled to 1-5 to match the other well-being measures.

**Affective valence** was measured with a single item: "How are you feeling right now?" [@KillingsworthGilbert2010Wandering]. Participants responded using a 100-point visual analogue scale (VAS) with endpoints "Very bad" and "Very good", which we rescaled to 1-5 to match the other well-being measures.

**Gaming life fit** was measured with a draft measure asking players to rate the contribution of gaming to 5 life domains (work/school, social participation, cognitive health, emotion regulation, and daily routines) on a 7-pt bipolar scale from "greatly interfered" to "greatly supported". We took the average of these to generate a formative indicator of the degree to which players perceive their gaming to be beneficial or harmful to other aspects of their lives. This measure has not been used or validated before, and we return to this in the discussion.

## Analytic Approach

To test H1, we fit multiple regression models with playtime over the previous 2 weeks as the primary predictor, all demographic variables as covariates (age, gender, highest level of education, and employment status), and the corresponding mental health variable as the outcome. For example, for H1a (life satisfaction predicted by the previous 2 weeks of play), the model in R is:

{{lm((life satisfaction) \~ (playtime in the previous 2 weeks) + age + gender + education + employment)}}

We apply a similar analysis approach to our exploration of H2 concerning other timescales; we primarily apply multiple regression with well-being predicted by playtime aggregated over various time periods and the same covariates, but also explore potential non-linear alternatives and moderation analyses (detailed below).

We interpret the playtime coefficient estimates from these models in reference to pre-specified smallest effect sizes of interest (see below): if the 99% confidence interval is fully within the upper and lower equivalence bounds, this provides evidence to reject a practically meaningful association.

We conducted all statistical analyses with R version 4.3.2 [@RCoreTeam2023language]. We use an alpha of .01.

## Smallest Effect Size of Interest

We specify the smallest effect size of interest (SESOI) as a 1-hour change in (daily) playtime associated with a .06 scale point change in mental health on a 1–5 scale, in line with @BallouEtAl2024Registered, who justified that value based on previous research on minimally important differences (approximately .3–.4 scale points on a 1–5 scale for PROMIS and WEMWBS measures) and daily leisure time available to US adults (approximately 5 hours; @SturmCohen2019Free). Any association smaller than .06 indicates that the average person does not have enough time in the day to modulate their play to an extent that it would register a perceptible difference in their well-being.

Note: this method of specifying an SESOI is predicated on a causal interpretation—it implicitly imagines a world where one can intervene on the predictor (playtime) and have an effect of a certain size on the outcome (mental health). It is very unlikely that our cross-sectional analyses can provide unbiased causal estimates. Instead, our goal is to use associations to place boundaries on the size of a possible effect: if there is no meaningful correlation between playtime and mental health, there is even less likely to be a meaningful causal effect between playtime and mental health. We support this reasoning with simulations presented in the discussion.

# Results

## Descriptive results

```{r}
#| label: playtime-quantiles
#| eval: false

playtime <- median_qi(dat, playtime2wk*14, .width = .7, na.rm = TRUE) |> 
  mutate(across(where(is.numeric), ~round(., 2)))
playtime <- str_glue("{playtime[1]} ({playtime[2]}, {playtime[3]}; 2nd and 8th deciles)")

quantile(dat$playtime2wk, probs = seq(.1, .9, by = .1), na.rm = TRUE)
```

```{r}
#| label: fig-playtime
#| fig-cap: "Description of playtime in the sample. Panel A shows the distribution of playtime across players for each observation period, with the mean shown in red; observations periods below the dashed line are shown as total hours, whereas periods above the dashed line reflect hours of player per day. Panel B shows the proportion of players who logged at least one play session in that period."
#| fig-width: 8
#| fig-height: 6
#| fig-align: center
#| fig-pos: "t"
#| apa-twocolumn: true

p1 <- dat |> 
  select(pid, matches("playtime\\d")) |> 
  pivot_longer(-pid) |> 
  mutate(name = fct_rev(fct_recode(name, !!!playtimeDict))) |> 
  mutate(name = fct_inorder(name)) |> 
  ggplot(aes(value, name)) +
  geom_point(alpha = .6) +
  geom_hline(yintercept = 5.5, linetype = "dashed") +
  stat_summary(fun = mean, col = "red") +
  labs(
    x = "Hours of (daily) play",
    y = "Observation Period"
  ) +
  scale_x_continuous(limits = c(0, 6), 
                     breaks = c(0, 1, 2, 3, 4, 5, 6)) +
  mytheme

p2 <- dat |> 
  select(pid, matches("played\\d")) |> 
  mutate(across(where(is.logical), as.numeric)) |> 
  pivot_longer(-pid) |> 
  mutate(name = fct_rev(fct_recode(name, !!!playedDict))) |> 
  mutate(name = fct_inorder(name)) |> 
  summarise(
    n = sum(value),
    .by = c(name)
  ) |> 
  ggplot(aes(n, name)) +
  scale_x_continuous(
    "Participants",
    sec.axis = sec_axis(
      ~ . / length(unique(dat$pid)), name = "Proportion"
    )
  ) +
  labs(y = "") +
  geom_point() +
  mytheme

(p1 | p2) + plot_layout(axes = "collect") + plot_annotation(tag_level = "A")

```

Given the lack of holistic or platform-level data available in the literature, our first goal was to simply describe the volume of play. This is visualized in @fig-playtime, which show that despite a total play volume of more than 140k hours, our sample was largely minimally engaged with 1st party Nintendo games. During the 2 weeks prior to survey completion, just over half of the sample had 0 sessions logged. The top 10% of players were moderately engaged, playing an average of 60 minutes per day. Sessions of a game lasted on average `r round(median(datRaw$duration, na.rm = T), 1)` minutes \[10th percentile: `r quantile(datRaw$duration, .1)`; 90th percentile: `r quantile(datRaw$duration, .9)`\].

The results of this study are therefore reflective of a largely casual population of players—at least with respect to Nintendo titles. We argue that this population is nonetheless an important one: if video games were to meaningfully affect well-being, we may expect a larger impact for people who rarely play but happen to play for 1 hour, than for a highly engaged population of people who tend to play 3 hours per day, but happen to play 4 hours. We return to this limitation on generalizability in the discussion.

## H1: Previous 2 weeks of playtime and mental health

```{r}
#| label: h1-models
#| include: false

h1csas <- lm(csas ~ playtime2wk + age + genderRC + eduLevel + employment, data = dat)
h1affect <- lm(affectiveValence ~ playtime2wk + age + genderRC + eduLevel + employment, data = dat)
h1promis <- lm(meanPromis ~ playtime2wk + age + genderRC + eduLevel + employment, data = dat)
h1wemwbs <- lm(meanWemwbs ~ playtime2wk + age + genderRC + eduLevel + employment, data = dat)

h1aCoef <- str_glue("(B = {number(coef(h1csas)[2], .01)} 99% CI [{number(confint(h1csas, level = .99)[2,1], .01)}, {number(confint(h1csas)[2,2], .01)}])")
h1bCoef <- str_glue("(B = {number(coef(h1affect)[2], .01)} 99% CI [{number(confint(h1affect, level = .99)[2,1], .01)}, {number(confint(h1affect, level = .99)[2,2], .01)}])")
h1cCoef <- str_glue("(B = {number(coef(h1promis)[2], .01)} 99% CI [{number(confint(h1promis, level = .99)[2,1], .01)}, {number(confint(h1promis, level = .99)[2,2], .01)}])")
h1dCoef <- str_glue("(B = {number(coef(h1wemwbs)[2], .01)} 99% CI [{number(confint(h1wemwbs, level = .99)[2,1], .01)}, {number(confint(h1wemwbs, level = .99)[2,2], .01)}])")
```

```{r}
#| label: assumption-checks
#| eval: false

# Checking the assumptions, we can see that there are major problems with normality of residuals
performance::check_model(h1csas)
performance::check_model(h1affect)
performance::check_model(h1promis)
performance::check_model(h1wemwbs)
```

```{r}
#| label: fig-scatter
#| fig-cap: Scatterplots depicting the relationship between video game playtime during the previous 2 weeks (mean minutes of play per day) and four types of well-being.
#| fig-width: 8
#| fig-height: 6
#| fig-align: center
#| fig-pos: "t"
#| apa-twocolumn: true

dat |> 
  pivot_longer(cols = c("csas", "affectiveValence", "meanPromis", "meanWemwbs")) |>
  mutate(name = case_when(
    name == "csas" ~ "Life Satisfaction",
    name == "affectiveValence" ~ "Affect",
    name == "meanPromis" ~ "Depressive Symptoms",
    name == "meanWemwbs" ~ "General well-being",
    TRUE ~ NA_character_
    )) |> 
  ggplot(aes(x = playtime2wk*60, y = value)) +
  geom_point(size = .6) +
  geom_smooth(method='lm', formula = y~x, level = .99, color = "darkgreen", fill = "darkgrey") +
  scale_x_sqrt(breaks = c(0, 15, 60, 120, 240, 420)) +
  labs(x = "Minutes of play per day\nduring previous 2 weeks (Square Root Axis)", y = "Outcome (1-5 scale)") +
  mytheme +
  # theme(
  #   axis.line.y = element_line(linewidth = .5)
  # ) + 
  # scale_y_continuous(labels = scales::percent) +
  facet_wrap(~name)
  
# plot_predictions(h1csas, condition = "playtime2wk") # test with marginaleffects
```

We began by analyzing H1, which concerned the relationship between mental health and the previous 2 weeks of playtime. This time period is common in the literature, and served as a way to conceptually replicate a previous study focused on one game [@JohannesEtAl2021video] using platform-level data.

Results are visualized in @fig-playtime. Multiple regression models found no evidence that people who played 1 additional hour per day in the previous 2 weeks differed from their peers with regard to life satisfaction `r h1aCoef`, affect `r h1bCoef`, depressive symptoms `r h1cCoef`, or general mental well-being `r h1dCoef`.

However, due to lower than expected response rates and total volume of playtime, there is too much uncertainty around our estimates to confidently reject the presence of a meaningful relationship using our original SESOI of .06; following our inference criteria, the results of our original hypothesis tests are all inconclusive. We therefore interpret our results as indicating an *absence of evidence* for a relationship between playtime and well-being, but do not conclude *evidence of absence*.

## H2: Exploration of other playtime windows

```{r}
#| label: model-fitting

models <- expand.grid(predictor = dat |> select(matches("playtime\\d")) |> names(),
                      outcome = c("csas","affectiveValence","meanWemwbs","meanPromis")) |> 
  mutate(formula = paste0(outcome, " ~ ", predictor, " + age + genderRC + eduLevel + employment"))

fittedModels <- map_df(
  models$formula, ~lm(as.formula(.x), 
                      data = dat) |> 
    broom::tidy(conf.int = TRUE, conf.level = .99) |> 
    filter(grepl("play", term))
) |> 
  mutate(predictor = models$predictor,
         outcome = models$outcome) |> 
  select(predictor, outcome, everything())
```

```{r}
#| label: fig-ests
#| fig-cap: Estimates for the relationship between playtime and well-being across various timescales, shown with 90% (dark blue) and 99% (light blue) confidence intervals. Dashed lines represent the positive and negative smallest effect size of interest (SESOI) of .06. 
#| fig-width: 8
#| fig-height: 6
#| fig-align: center
#| fig-pos: "t"
#| apa-twocolumn: true

fittedModels |> 
  mutate(
    model = paste0(outcome, " ~ ", predictor),
    predictor = fct_rev(fct_recode(predictor, !!!playtimeDict)),
    outcome = fct_recode(outcome,
                         "Life Satisfaction" = "csas",
                         "Affect" = "affectiveValence",
                         "Depressive Symptoms" = "meanPromis",
                         "General Mental Well-being" = "meanWemwbs"),
    
    # some hacky code to match up the time periods with their lubridate::period objects and then convert to numeric
    # so we can plot on the log scale
    window = map(sub("playtime", "", term), ~ timeWindows[.]),
    window = map_dbl(window, ~ as.numeric(.x[[1]], "hours")),
    conf.high.90 = estimate + 1.645*std.error,
    conf.low.90 = estimate - 1.645*std.error
  ) |>
  ggplot(aes(x = window, y = estimate)) +
  geom_ribbon(
    aes(ymin = conf.low, ymax = conf.high),
    group = 1,
    alpha = .4,
    fill = "darkgrey"
  ) +
  geom_ribbon(
    aes(ymin = conf.low.90, ymax = conf.high.90),
    group = 1,
    alpha = .8,
    fill = "darkgrey"
  ) +
  geom_line(
    group = 1,
    color = "darkgreen",
    linewidth = 1,
  ) +
  geom_point(color = "darkgreen", size = 2) +
  scale_x_log10(breaks = map_dbl(timeWindows, ~ as.numeric(.x[[1]], "hours")), labels = names(playtimeDict)) +
  labs(
    x = "Observation period for video game play",
    y = "Playtime-outcome association\nin observation period"
  ) +
  theme_linedraw() +
  theme(
    # axis.title.y = element_text(angle = 0, vjust = .5),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(linewidth = .1)
    ) +
  geom_hline(yintercept = .06, linetype = "dashed", linewidth = .3, color = "black") +
  geom_hline(yintercept = -.06, linetype = "dashed", linewidth = .3, color = "black") +
  facet_wrap(~outcome, scales = "free_y")

```

Next, we conducted exploratory analyses to understand if the relationship between playtime and well-being varies across different playtime periods (@fig-ests). Broadly, results align with the results of H1---in all models, 99% CIs overlapped 0, but due to low precision no estimate was fully within the equivalence bounds. We therefore do not find evidence for a meaningful relationship between playtime and well-being at any timescale, but cannot rule out the possibility of one existing.

Estimates are especially uncertain for observation periods of 6 hours or less, as few participants played Nintendo shortly before completing a survey. However, there is a trend towards stronger relationships among more recent observation periods: based on the point estimates, playtime within the previous 1--2 hours is more strongly correlated with well-being than medium- and longer-term time periods. In each case, playtime shortly before completing a survey was associated with higher affect, life satisfaction, and general mental well-being; and with lower levels of self-reported depressive symptoms.

## Exploratory analysis: Moderation by life fit

```{r}
#| label: moderation
#| include: false

moderationModels <- expand.grid(predictor = dat |> select(matches("playtime\\d")) |> names(),
                      outcome = c("csas","affectiveValence","meanWemwbs","meanPromis")) |> 
  mutate(formula = paste0(outcome, " ~ ", predictor, "*meanLifeFit + ", predictor, "*age + ", predictor, "*genderRC"))

moderationFits <- map_df(
  moderationModels$formula, ~lm(as.formula(.x), 
                                data = dat) |> 
    broom::tidy(conf.int = TRUE, conf.level = .99)
) |> 
  mutate(predictor = rep(moderationModels$predictor, each = 10),
         outcome = rep(moderationModels$outcome, 10)) |> 
  select(predictor, outcome, everything())

directEsts <- moderationFits |> 
  filter(!grepl("playtime", term) & grepl("meanLifeFit", term)) |>
  # filter(!grepl(":", term)) |> 
  mutate(across(estimate, abs),
         across(where(is.numeric), ~round(., 3)))

moderationEsts <- moderationFits |> 
  filter(grepl(":meanLifeFit", term)) |> 
  # filter(grepl("playtime", term) & grepl("Displace", term)) |> 
  mutate(across(where(is.numeric), ~round(., 3)))
```

```{r}
#| label: fig-lifefit
#| fig-cap: Marginal relationship between gaming life fit (perceived harmful or beneficial effects of games for oneself) and wellbeing 
#| fig-width: 8
#| fig-height: 6
#| fig-align: center
#| fig-pos: "t"
#| apa-twocolumn: true

lifeFitCsas <- lm(csas ~ meanLifeFit*playtime2wk + age + genderRC + eduLevel + employment, data = dat)
lifeFitAffect <- lm(affectiveValence ~ meanLifeFit*playtime2wk + age + genderRC + eduLevel + employment, data = dat)
lifeFitPromis <- lm(meanPromis ~ meanLifeFit*playtime2wk + age + genderRC + eduLevel + employment, data = dat)
lifeFitWemwbs <- lm(meanWemwbs ~ meanLifeFit*playtime2wk + age + genderRC + eduLevel + employment, data = dat)

preds <- rbind(
  plot_predictions(lifeFitCsas, condition = "meanLifeFit", draw = FALSE) |> mutate(model = "Life Satisfaction") |> rename(wb = csas),
  plot_predictions(lifeFitAffect, condition = "meanLifeFit", draw = FALSE) |> mutate(model = "Affective Valence") |> rename(wb = affectiveValence),
  plot_predictions(lifeFitPromis, condition = "meanLifeFit", draw = FALSE) |> mutate(model = "Depressive Symptoms") |> rename(wb = meanPromis),
  plot_predictions(lifeFitWemwbs, condition = "meanLifeFit", draw = FALSE) |> mutate(model = "General Mental Well-being") |> rename(wb = meanWemwbs)
)

ggplot(preds, aes(x = meanLifeFit, y = estimate)) +
  geom_point(
    data = dat |> pivot_longer(cols = c(affectiveValence, meanPromis, meanWemwbs, csas), 
                               names_to = "model", values_to = "wellbeing") |> 
      mutate(model = recode(model, 
                                "affectiveValence" = "Affective Valence",
                                "csas" = "Life Satisfaction",
                                "meanPromis" = "Depressive Symptoms",
                                "meanWemwbs" = "General Mental Well-being")), 
    aes(x = meanLifeFit, y = wellbeing, group = model), alpha = .1) +
  geom_line(color = "darkgreen", linewidth = 1.5) +
  geom_ribbon(
    aes(ymin = conf.low, ymax = conf.high),
    group = 1,
    alpha = .2,
    # fill = "darkred"
  ) +
  facet_wrap(~ model, scales = "free_y") +
  labs(x = "Mean Gaming Life Fit", y = "Wellbeing (1-5 Scale)") +
  mytheme

```

Next, we conducted exploratory analyses to investigate what other factors might influence who exhibits positive or negative relations between gaming and well-being. We explored age, gender, and life fit---the perceived harmful or beneficial value of gaming in various life domains. We expected that people who perceive gaming to support other life domains would exhibit a more positive relationship between gaming and mental health, and those who perceived gaming to be harmful to other life domains would exhibit a more negative relationship.

To test this, we reran the models from H2, adding `playtime * age`, `playtime * gender`, and `playtime * lifeFit` moderation terms. We did not find evidence to support the presence of moderation; none of the moderation terms were significant (`r min(moderationEsts$p.value)` \< ps \< `r max(moderationEsts$p.value)`).

However, we did find a direct relationship between greater life fit and greater well-being separate from playtime (@fig-lifefit): People who believe gaming to be more beneficial to their lives tend to also report higher well-being, regardless of how much they play. Across 48 models, we observed relationships between well-being and a 1 point change in life fit ranging from `r min(directEsts$estimate)` to `r max(directEsts$estimate)` (median = `r round(median(directEsts$estimate), 3)`; all ps \< .001).

## Sensitivity Checks

```{r}
#| label: sensitivity-linearity
#| include: false

# Here we explore potential non-linearity in the relationships between playtime and mental health by e.g. comparing a generalized additive model of well-being with and without a smooth term for playtime, and comparing AIC between these.

nonlinearity <- dat |> 
  select(affectiveValence, meanPromis, meanWemwbs, csas, contains("playtime")) |> 
  pivot_longer(matches("playtime\\d"), names_to = "window", values_to = "playtime") |> 
  pivot_longer(cols = c(affectiveValence, meanPromis, meanWemwbs, csas), 
               names_to = "measure", values_to = "wellbeing") |>
  group_by(measure, window) |> 
  nest() |> 
  mutate(
    linear = map(data, ~gam(wellbeing ~ playtime, data = .x)),
    smooth = map(data, ~gam(wellbeing ~ s(playtime, k = 5), data = .x))
  ) |>
  pivot_longer(linear:smooth, names_to = "Model") |> 
  mutate(AIC = map_dbl(value, AIC)) |> 
  select(-value) |> 
  pivot_wider(names_from = Model, values_from = AIC) |> 
  mutate(Difference = linear-smooth)

```

```{r}
#| label: sensitivity-duration
#| include: false

nintendoModels <- expand.grid(predictor = dat |> select(matches("playtimeNintendo\\d")) |> names(),
                      outcome = c("csas","affectiveValence","meanWemwbs","meanPromis")) |> 
  mutate(formula = paste0(outcome, " ~ ", predictor, " + age + genderRC"))

nintendoFits <- map_df(
  models$formula, ~lm(as.formula(.x), 
                      data = dat) |> 
    broom::tidy(conf.int = TRUE, conf.level = .99) |> 
    filter(grepl("play", term))
) |> 
  mutate(predictor = nintendoModels$predictor,
         outcome = nintendoModels$outcome) |> 
  select(predictor, outcome, everything())

nintendoFits |> 
  mutate(
    model = paste0(outcome, " ~ ", predictor),
    predictor = fct_rev(fct_recode(predictor, !!!nintendoDict)),
    outcome = fct_recode(outcome,
                         "Life Satisfaction" = "csas",
                         "Affect" = "affectiveValence",
                         "Depressive Symptoms" = "meanPromis",
                         "General well-being" = "meanWemwbs")
  ) |> 
  ggplot(
    aes(y = predictor,
        fill = predictor,
        xdist = dist_normal(estimate, std.error))
  ) +
  geom_vline(xintercept = 0, color = "grey") +
  stat_halfeye(position = position_dodge(.5), # distance between slabs within a group
               normalize = "groups",
               .width = .99, # width of pointrange conf int
               scale = .7) + # height of density plots
  geom_vline(xintercept = -.06, linetype = "dashed") +
  geom_vline(xintercept = .06, linetype = "dashed") +
  scale_x_continuous(limits = c(-.5, .5), breaks = seq(-.5, .5, .1)) +
  scale_fill_viridis_d(option = "magma", begin = .8, end = .4) +
  labs(x = "Difference in well-being (1-5 scale)\nAssociated with 1 Additional Hour of Daily Playtime",
       y = "Playtime Window") +
  geom_text(aes(x = -.25,
                label = str_glue("{number(estimate, .01)} [{number(conf.low, .01)}, {number(conf.high, .01)}]")),
            vjust = -.3,
            size = 3,
            hjust = 1,
            position = position_dodge(.5)) +
  annotate(x = -.06, y = +Inf, label = "SESOI", vjust = 2, geom = "label") +
  annotate(x = .06, y = +Inf, label = "SESOI", vjust = 2, geom = "label") +
  mytheme +
  theme(legend.position = "none",
        axis.text.y = element_text(hjust = 1)) +
  facet_wrap(~outcome)
```

```{r}
#| label: sensitivity-binaryplay
#| include: false

binaryModels <- expand.grid(predictor1 = dat |> select(matches("played\\d")) |> names(),
                      outcome = c("csas","affectiveValence","meanWemwbs","meanPromis")) |> 
  mutate(predictor2 = rep(dat |> select(matches("playtime\\d")) |> names(), times = 4)) |> 
  mutate(formula = str_glue("{outcome} ~ {predictor1} + sqrt({predictor2}) + age + genderRC + eduLevel + employment"))

binaryFits <- map_df(
  binaryModels$formula, ~lm(as.formula(.x), 
                      data = dat) |> 
    broom::tidy(conf.int = TRUE, conf.level = .99) |> 
    filter(grepl("play", term))
) |> 
  mutate(predictor = rep(binaryModels$predictor1, each = 2),
         outcome = rep(binaryModels$outcome, each = 2)) |>
  select(predictor, outcome, everything())
```

We performed various sensitivity checks to ensure the robustness of our findings (see supplementary materials for full detail). First, we explored potential non-linearity in the relationships between playtime and mental health by comparing a generalized additive model of well-being with and without a smooth term for playtime, and comparing AIC between these. Of the 48 possible models (4 well-being variables \* 12 playtime windows), just 1 of these (playtime in the previous 1 year and life satisfaction) showed a difference in AIC of more than 2, indicating that nearly all relationships were adequately captured by linear terms. Next, we reran the analyses using session durations as calculated by Nintendo, as opposed to the implied duration based on the start and end timestamps; Nintendo's durations differ from the implied duration in approximately 10% of sessions, reflecting certain unknown heuristics used by Nintendo to calculate playtime (based e.g., on idle time, time spent in menus, and so on). Data show a similar pattern: no models showed a significant relationship between playtime and well-being at our specified alpha of .01. Next, we explored alternative models wherein playtime was separated into both a binary variable (1 if the player had any time logged in that period, 0 if not), and a continuous variable (how much a person played). Results were comparable; although three models indicated that among those who played in the previous 1-2 weeks, longer play is associated with higher affect and general mental well-being, the remaining 93 playtime variables were neither significant or nor within both equivalence bounds.

# Discussion

Although we did not design our study to test the causal question most critical to stakeholders, our study is a concrete step in the right direction, having independently recruited a large sample of video game players [as opposed relying on recruitment through games companies themselves; e.g. @JohannesEtAl2021video], collected validated measures of well-being, joined these with objective behavioral telemetry and made minimal adjustments for age, gender, employment, and education. Using these methods, we did not find robust or consistent relationships between time spent playing and various mental well-being outcomes.

Although not conclusive, our results point toward a pattern whereby platform-wide video game play time does not predict well-being to a meaningful degree. This trend, across a wide range of outcomes, timescales of play, and model specifications adds to a growing body of work that suggests that simple time spent playing games is unlikely to affect well-being for the average player. Said differently, the findings we report place the onus on those who assert that there is a meaningful relationship between playtime and well-being. It should be a priority to identify and concretely articulate which confounds might bias a true effect towards the null associations reported in this and other research using player telemetry [@JohannesEtAl2021video; @VuorreEtAl2022Time; @LarrieuEtAl2023How; @BallouEtAl2024Registered].

To further elucidate this point, we conducted brief simulation tests to ascertain how strong such confounding might need to be (see Supplementary Materials). For example, if the true standardized effect of playtime on mental health was a moderate .2 SDs per additional hour of daily playtime, a confound C would need to be a very strong cause of both X ($beta = .5$) and Y ($beta = -.5$ ) to bias the true .2 effect to null. While we do not claim this is impossible, we do believe it unlikely. Approaching the topic along these lines---identifying confounds, testing the presence or absence of correlations for their sensitivity to potential confounds, and systematically identifying factors that do (not) cause playtime and well-being---can help us achieve more systematic progress [@BallouEtAl2024How]. This work can be bolstered by qualitative research aimed at more fully mapping the causal system and by substantive theory development with greater specificity in the aspects of media use expected to produce effects, the hypothesized causal relationships, boundary conditions, and so forth [@MagnussonEtAl2024Harmful; @Ballou2023Manifesto; @Coenen2023Lost; @EronenBringmann2021theory].

## Who are "gamers"?

The steady attrition throughout the stages of the research process from screening, to linking, to successful data retrieval highlights the challenges for participant recruitment in video games research. Despite a series of filtering steps wherein a majority of participants were filtered out due to not playing Switch games or being unwilling or unable to link data, our final sample remains only minimally engaged with Nintendo games—playing just `r 7*round(median(dat$playtime1yr, na.rm = TRUE), 1)` hours per week on average. As a result, the population here is very different than previous studies whereby players were recruited through targeted emails from games companies [@JohannesEtAl2021video; @LarrieuEtAl2023How] or social media forums for highly-engaged players [@BallouEtAl2024Registered].

As argued above, we believe this is a valuable group in its own right—people who rarely play video games may be particularly susceptible to their positive or negative effects on the occasions they do play. While the current study is unlikely to generalize to so-called "hardcore" players who play several hours per day or more and therefore may experience more accumulative effects, our findings align with previous studies of more highly engaged players and add a new subgroup of players to the body of work showing the absence of any meaningful relationship [@BallouEtAl2024Registered; @LarrieuEtAl2023How; @VuorreEtAl2022Time].

As the field progresses, however, differences in the level of engagement pose major challenges for generalizability. Calls for representative samples need to specify the population of reference: should this be the general population (of whom many do not play games), people who play any games at all (of whom many do not play the games for which researchers have data access), people who play the particular game or platform of interest (of whom many may be only minimally engaged), or something else entirely? In the field's quest for more generalizable results, this will be a critical issue.

## Timescales

While we are quick to caution that this is a preliminary finding that should not be relied upon without further validation, our data provide some initial evidence that effects of raw playtime may be most likely to materialize and fade within a few hours---point estimates indicated that playtime was more strongly linked with greater well-being in the 1-2 hours prior to survey completion. This finding is compatible with various causal explanations: for example, players who recently played are more likely be in a period of leisure time, which would be expected to generate more positive feelings than in peers doing obligatory activities such as work. However, if researchers do expect to see positive effects of gaming, our data suggest that they may need to search for very local effects directly during and following a play session [e.g., @VuorreEtAl2024Affective].

Should this finding be upheld, it would go a long way towards explaining previous null findings from studies that related well-being to playtime over timescales such as 2 weeks [@VuorreEtAl2022Time], 1 month [@SibillaEtAl2021Harmonious], 6 months [@WeinsteinEtAl2017prospective], and 1 year [@KowertEtAl2015Psychosocial]. For most players, it may be the case that gaming is a recovery activity that helps to manage day-to-day stresses and mood fluctuations, without necessarily having substantial long-term impacts. The majority of players have several options for activities in their environment that would have comparable effects on their well-being. Such activities are thus “exchangeable”, serving the same short-term goals without consequences for long-term adjustment. Studying relationships over the course of hours has to date been possible largely only in laboratory settings—rarely have researchers had access to session-level data of naturalistic behavior that they could link to momentary well-being.

## Life fit

This study demonstrates the potential usefulness of life fit as a theoretical construct [@BallouDeterding2023Basic]. Given the accumulating evidence that playtime and well-being are not meaningfully related at the population level alongside incontrovertible evidence that some players benefit and some are harmed [@BallouEtAl2024How; @BallouEtAl2024How], the task for the field can be framed as a search for the most important moderators. Life fit—a player's self-assessment about the contribution of gaming to different aspects of their lives—stands as an effective starting point, letting researchers trust the lived experiences of players to guide them towards patterns of problematic or particularly beneficial play.

Using this measure, we found no evidence that life fit moderated the relationship between playtime and well-being, but we did find a direct correlation between the two. Notably, this relationship was an order of magnitude stronger than any estimates for playtime itself. Among several other possible explanations, this would fit a pattern of biased self-assessment: it is possible that players who are generally feeling poorly are more likely to appraise their gaming as harmful to their mental health, regardless of whether that mechanism actually takes place. This would align with some previous findings that more depressed people tend to overestimate their smartphone use due to a negative or guilt-laden appraisal process distinct from the media use itself [@SewallParry2021Role].

We caution that the measure applied here has not been validated, and is better viewed as a formative indicator than as a true latent variable. More work will be needed to understand the validity of this construct.

## Holistic digital trace data

This paper demonstrates both the value and difficulty of collecting holistic digital trace data: by capturing data across an entire platform, rather than just one game, we can potentially account for a person’s complete engagement with games without self-report biases—but only if we sample players for whom that platform constitutes the majority of their gaming. Our screening data indicates that participants play games on average across 2.8 platforms, for example playing games across Nintendo, Steam, and iOS. To fully capture players' entire gaming diets, researchers will need to either subsample participants who use only one platform or develop distinct methods of collecting digital trace data for several platforms.

In this same vein, although collaborations between academics and digital media platforms are becoming incrementally more common [e.g., @NyhanEtAl2023Likeminded; @LarrieuEtAl2023How], these remain difficult to source and stubbornly inequitably distributed across the research ecosystem. Researchers are actively exploring other ways to source digital trace data, including through scraping methods [@BallouEtAl2024Registered], APIs (e.g., <https://gameplay.science>), and subject data access requests/data download packages [@BreuerEtAl2022Usercentric], but more needs to be done. Relationships between games firms and independent research teams are not scalable and the providence of data collected by scraping and related tools is difficult if not impossible to verify. Democratizing researcher access in a way that protects participants' autonomy and right to privacy will require the enactment of multisector-spanning initiatives like the UK’s Video Game Research Framework [@DepartmentforMediaCultureandSport2023Video] that clearly prescribe the responsibilities for those enabling, enacting, and benefiting from the scientific study of video game play. The time for this is well past due.

## Limitations

There are three limitations and constraints on generalizability the merit mention. First, the most pronounced limitation is that we cannot analyze telemetry generated when players engaged with third-party titles (i.e. games not published by Nintendo or its closely associated companies). As a result, our findings generalize only to similar Nintendo games (75% of which were rated for everyone or everyone over 10), and it is not possible to rule out the possibility that third-party games with different content or themes might show a different pattern of effects. Likewise, because we collaborated with Nintendo of America, our sample consisted only of adults living in the United States, a group that we found to be largely casually involved with first-party Nintendo games. Games are both global and played by those of all ages, so it is not clear the degree to which our findings do or do not generalize to younger players, those who play other games, or those who approach games from varied cultural and linguistic backgrounds. Finally, while we have longitudinal telemetry data, we were constrained here to a single cross-sectional wellbeing survey: we intend to expand upon these findings with more granular wellbeing measures in the future, and encourage the field to follow other media use disciplines and embrace daily diary and experience sampling methods [e.g., @SiebersEtAl2021Explaining; @AalbersEtAl2021Caught].

```{r}
#| label: game-metadata
#| eval: false

metadata <- read_csv(paste0(Sys.getenv("DATA_PATH"), "gameMetadata.csv.gz"))

games <- datRaw |> 
  filter(!(pid %in% c(clockHackers, nonPlayers))) |> 
  group_by(titleID) |> 
  summarise(totalPlay = sum(duration, na.rm = TRUE)) |> 
  left_join(metadata, by = c("titleID" = "NoAname")) |> 
  group_by(gameID) |> 
  arrange(desc(totalPlay)) |> 
  slice(1) |> 
  arrange(desc(totalPlay)) |> 
  ungroup()

genres <- games |> 
  separate_rows(genres, sep = ",") |> 
  mutate(presence = TRUE) |> # placeholder
  pivot_wider(names_from = genres, values_from = presence, values_fill = list(presence = FALSE)) |> 
  summarise(across(c(`Role-playing (RPG)`:MOBA), 
                   list(
                     prop_games = ~ mean(.x),
                     prop_time = ~ sum(.x * totalPlay) / sum(games$totalPlay)),
                   .names = "{.col}_{.fn}")) |> 
  pivot_longer(cols = everything(), 
               names_to = c("genre", ".value"), 
               names_sep = "_prop_")


table(games$rating_ESRB)
table(games$genres)
```

## Conclusion

The idea that time spent playing is the key ingredient in how games impact well-being will be with us for some time. Although our study was not designed to test a causal link, it challenges the notion that simply playing more affects well-being, for better or for worse. The correlations we observed were mostly too small to practically matter. Moreover, we show that large confounding would be required to suppress a true causal effect to produce the null associations we observed. This is improbable but not impossible, and we believe our results lend weight to calls for scholars and health practitioners to embrace the gradual shift of focus towards quality, rather than quantity of video game play as the key factor for player health. If this can be done while simultaneously improving data quality and access, a coherent and evidence-based method for studying the complex relationships linking video game play and well-being will be possible.

# References

::: {#refs}
:::
